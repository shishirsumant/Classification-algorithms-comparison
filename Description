A comparative study has been done on the performance of three classification algorithms in this project. The algorithms are:
1) Support Vector Machines
2) Decision Trees
3) Artificial Neural Networks
The comparison of performance is based on the Training speed, Prediction speed and Prediction accuracy.
Dataset used: The dataset used is heart disease dataset taken from UCI machine learning database and has 720 instances of patients with each patient having 76 attributes. The link to download the dataset is as follows: https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/
In our project, 14 of these attributes are taken for consideration. The dataset has some invalid values, the rows with such invalid values are omitted giving us a total of 714 instances. The dataset is present in CSV format. 
Algorithms:
1)	Support Vector Machines: It is a Supervised machine algorithm that can be used for both classification and regression but mostly used for classification. The idea of algorithm is to plot each data item as a point in n-dimensional space with the value  of each feature being the value of a particular co-ordinate, where n is number of features. Classification is done by finding the hyper-plane that differentiates the two classes very well. In our case, We have incorporated libraries from Scikit-Learn in python which makes it very easy to use SVM. The kernel used is non-linear ‘Radial Basis Function’ due to high dimensionality. An optimal C of 0.1 is used to prevent the problem of overfitting. The dataset is split into train data and test data and for a split of 80%train data to 20% test data, the system gave an accuracy of approximately 72.72%.

2)	Neural Networks: A neural network consists of units(neurons), arranged in layers, which convert an input vector into output. Each unit takes an input, applies an activation function to it, and then passes the output on to the next layer. Weights are applied to the signals passing from one unit to the other. The final output is compared with the output defined in the dataset, the error is calculated. The idea of the neural network is to minimize the error by tuning the weights. This process is called training. In our program, we have used Adam optimizer provided by the TensorFlow library, with a learning rate of 0.001. The network has one input layer, two hidden layers with 10 and 5 activation units, and an output layer, the activation function used is exponential linear unit. The network was trained with 70%, 80% and 90% of dataset and tested with 30%, 20% and 10% of the dataset respectively. On an average network took around 27 seconds to train, with a prediction accuracy of 85%.


3)	Decision Tree: ID3 algorithm is used to build the decision tree. ID3 is a greedy algorithm that constructs the decision tree by obtaining the best decision attribute at every node. Best decision attribute is the one which gives maximum information gain, which is calculated by determining the entropy of attribute with respect to the target attribute. In our case, The libraries for decision tree have been incorporated from scikit-learn. The accuracy of the system for a split of 80% train data to 20% test data was 69.42%
